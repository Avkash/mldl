{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(999)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Sequential model type from Keras. This is simple a linear stack of neural network layers, \n",
    "# and it's perfect for the type of feed-forward CNN we're building in this tutorial.\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import \"core\" layers from Keras. These are the layers that are used in almost any neural network:\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the CNN layers from Keras. \n",
    "# These are the convolutional layers that will help us efficiently train on image data:\n",
    "from keras.layers import Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import  utilities to transform our data later\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    " \n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the data sets now\n",
    "# Training - X_train, y_train\n",
    "# Testing  - Y_test, y_test\n",
    "# Try all objects as below to understand\n",
    "print(X_train) \n",
    "# Note: You will see that all the objects here are int32 type. (Reminder for later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are geting the size of each object so we can understand the train and test data better\n",
    "print(X_train.shape)\n",
    "# Note: X_train has 60,000 samples in training set, and the images are 28 pixels x 28 pixels each\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "# Note: The shape will print values as -> (n, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to look at specfic item in the array try this\n",
    "# Note:-- you will see the following gives the error as array items are 0 - 59999 > total 60000 \n",
    "#      -- print(X_train[60000])\n",
    "# Note:-- The following will work\n",
    "#      -- print(X_train[0])\n",
    "#      -- print(X_train[59999])\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X_train[1]) # Note: Sometimes you need to call pyplot.show() to display the image\n",
    "# Try this too -- plt.imshow(X_train[0], aspect = 'auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[1000], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNDERSTANDING showing image various ways\n",
    "fig1 = plt.figure() # create a figure with the default size \n",
    "\n",
    "#im1 = np.random.rand(5,5)\n",
    "ax1 = fig1.add_subplot(2,2,1) \n",
    "ax1.imshow(X_train[2], interpolation='none')\n",
    "ax1.set_title('5 X 5')\n",
    "\n",
    "#im2 = np.random.rand(50,50)\n",
    "ax2 = fig1.add_subplot(4,4,4)\n",
    "ax2.imshow(X_train[2000], interpolation='none')\n",
    "ax2.set_title('100 X 100')\n",
    "\n",
    "\n",
    "#im3 = np.random.rand(100,100)\n",
    "ax3 = fig1.add_subplot(10,10,5) \n",
    "ax3.imshow(X_train[999], interpolation='none')\n",
    "ax3.set_title('5 X 5')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now we are starting Preprocessing with KERAS **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note There is another way to flatten the image. The training dataset is structured as a 3-dimensional array of instance, image width and image height. \n",
    "# For a multi-layer perceptron model we must reduce the images down into a vector of pixels. \n",
    "# In this case the 28Ã—28 sized images will be 784 pixel input values.\n",
    "# We can do this transform easily using the reshape() function on the NumPy array. \n",
    "# We can also reduce our memory requirements by forcing the precision of the pixel values to be 32 bit, \n",
    "# the default precision used by Keras anyway.\n",
    "\n",
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "print(num_pixels)\n",
    "#X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "#X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "#NOTE: Above or Below Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With Theano, you must explicitly declare a dimension for the depth of the input image. \n",
    "# COLOR - For example, a full-color image with all 3 RGB channels will have a depth of 3.\n",
    "# MNIST images only have a depth of 1, but we must explicitly declare that.\n",
    "# Target: transforming dataset from having shape (n, width, height) to (n, depth, width, height)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Confirming that we have depth included in the images.\n",
    "print(X_test.shape)\n",
    "print(X_test.shape[0])\n",
    "print(X_test.shape[1])\n",
    "print(X_test.shape[2])\n",
    "print(X_test.shape[3])\n",
    "# (60000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert input data > data type to float32 and normalize our data values to the range [0, 1].\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You will see that the X_train object is of the float32 type now\n",
    "# Note:X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm... that may be problematic. \n",
    "# We should have 10 different classes, one for each digit, \n",
    "# Total items in the object\n",
    "print(y_train.shape)\n",
    "# Following shows 1-dimensional array of 60000 items\n",
    "print(y_train)\n",
    "# Let's take a look at the labels for the first 10 training samples or 1 to 11th\n",
    "print(y_train[:10])\n",
    "# Let's take a look at the labels from 1st to 11th\n",
    "print(y_train[1:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PROBLEM: The y_train and y_test data are not split into 10 distinct class labels\n",
    "#          both y_train and y_test data are represented as a single array with the class values.\n",
    "# Fix:     Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that both Y_train and y_test are two dimensional array\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Working on Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declaring a sequential model\n",
    "model = Sequential()\n",
    "# Note: If you call the following you will see that there is no layer added to the model\n",
    "# print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a CNN layer to the model\n",
    "\n",
    "# How to function is set for \"the number of convolution filters to use\"\n",
    "# Param 1: [32],the number of rows in each convolution kernel, \n",
    "# Param 2: [1] nb_row: Number of rows in the convolution kernel.\n",
    "# Param 3: [1] nb_col: Number of columns in the convolution kernel.\n",
    "# Note: The input_shape values are filled from (depth, width, height) >> print X_train.shape\n",
    "\n",
    "model.add(Convolution2D(32, 1, 1, activation='relu', input_shape=(1,28,28)))\n",
    "# Note: The input shape parameter should be the shape of 1 sample. In this case, \n",
    "#       it's the same (1, 28, 28) that corresponds to  the (depth, width, height) of each digit image.\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, 1, 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding epoch to model fit\n",
    "#### larger the number longer it will take to train\n",
    "#### larger the number, the better the model will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, \n",
    "          batch_size=32, nb_epoch=epoch_count, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train[0])\n",
    "print(y_train[0])\n",
    "print(X_train[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_1 = X_train[100].reshape(X_train[0].shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model.predict(X_1,batch_size=32, verbose=1)\n",
    "print(pred1)\n",
    "print(pred1[0])\n",
    "xbar = range(len(pred1[0]))\n",
    "print(xbar)\n",
    "plt.bar(xbar,pred1[0])\n",
    "print(np.argmax(pred1[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_1.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = np.argmax(pred1[0])\n",
    "print(label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_train[1].reshape(X_train[1].shape[0], 1, 28, 28)\n",
    "print(X_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model.predict(X_2,batch_size=32, verbose=1)\n",
    "print(pred2[0])\n",
    "print(np.argmax(pred2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
